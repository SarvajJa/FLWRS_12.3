{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b954b8b0",
   "metadata": {},
   "source": [
    "# Adjoint tutorial (toy ODE example)\n",
    "This notebook demonstrates adjoint gradient computation for a toy ODE parameter estimation problem: du/dt = -a*u + b, estimate a,b from final value. This illustrates the adjoint idea in a simple setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454adba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "# Toy forward solve: u' = -a u + b, u(0)=u0, analytic solution\n",
    "def forward(a,b,u0,t):\n",
    "    return (u0 - b/a) * np.exp(-a*t) + b/a\n",
    "a_true = 1.3; b_true = 0.5; u0 = 2.0; T = 1.0\n",
    "y_obs = forward(a_true,b_true,u0,T)\n",
    "eps = 1e-6\n",
    "def cost(a,b):\n",
    "    uT = forward(a,b,u0,T)\n",
    "    return 0.5*(uT - y_obs)**2\n",
    "grad_a = (cost(a_true+eps,b_true)-cost(a_true-eps,b_true))/(2*eps)\n",
    "grad_b = (cost(a_true,b_true+eps)-cost(a_true,b_true-eps))/(2*eps)\n",
    "print('FD grad approx:', grad_a, grad_b)\n",
    "# analytic gradient via chain rule\n",
    "def dudT_da(a,b,u0,T):\n",
    "    # derivative of solution wrt a computed manually\n",
    "    return (- (u0 - b/a)/a + (b/(a*a))) * np.exp(-a*T) + (u0 - b/a)*(-T)*np.exp(-a*T)\n",
    "def dudT_db(a,b,u0,T):\n",
    "    return (1/a) * (1 - np.exp(-a*T))\n",
    "# gradient of cost\n",
    "uT = forward(a_true,b_true,u0,T)\n",
    "grad_a_analytic = (uT - y_obs) * dudT_da(a_true,b_true,u0,T)\n",
    "grad_b_analytic = (uT - y_obs) * dudT_db(a_true,b_true,u0,T)\n",
    "print('analytic grad (should match FD):', grad_a_analytic, grad_b_analytic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0101fd8",
   "metadata": {},
   "source": [
    "This toy demonstrates the adjoint idea in a trivial analytic case. For PDE adjoints use the discrete adjoint algorithm in the paper and test with FD checks."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
